{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414aafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b90afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Hola! Estoy bien, gracias. ¿Y tú? ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt4o_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "response = gpt4o_llm.invoke(\"Hola como estas?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1718ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Tool real (Open-Meteo)\n",
    "# -------------------------\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Obtiene la temperatura actual (°C) de una ciudad usando Open-Meteo.\"\"\"\n",
    "    geo = requests.get(\n",
    "        \"https://geocoding-api.open-meteo.com/v1/search\",\n",
    "        params={\"name\": city, \"count\": 1, \"language\": \"es\", \"format\": \"json\"},\n",
    "        timeout=15,\n",
    "    ).json()\n",
    "\n",
    "    if not geo.get(\"results\"):\n",
    "        return json.dumps({\"error\": f\"No pude geocodificar '{city}'.\"}, ensure_ascii=False)\n",
    "\n",
    "    r0 = geo[\"results\"][0]\n",
    "    lat, lon = r0[\"latitude\"], r0[\"longitude\"]\n",
    "    resolved = f'{r0.get(\"name\", city)}, {r0.get(\"country\", \"\")}'.strip(\", \")\n",
    "\n",
    "    forecast = requests.get(\n",
    "        \"https://api.open-meteo.com/v1/forecast\",\n",
    "        params={\"latitude\": lat, \"longitude\": lon, \"current_weather\": True, \"temperature_unit\": \"celsius\"},\n",
    "        timeout=15,\n",
    "    ).json()\n",
    "\n",
    "    cw = forecast.get(\"current_weather\")\n",
    "    if not cw:\n",
    "        return json.dumps({\"error\": \"No pude obtener current_weather.\"}, ensure_ascii=False)\n",
    "\n",
    "    return json.dumps(\n",
    "        {\n",
    "            \"city_input\": city,\n",
    "            \"city_resolved\": resolved,\n",
    "            \"temperature_c\": cw.get(\"temperature\"),\n",
    "            \"time\": cw.get(\"time\"),\n",
    "            \"source\": \"open-meteo\",\n",
    "        },\n",
    "        ensure_ascii=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f28f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CASO A: LLM sin tools (solo prompt) ===\n",
      "Lo siento, no tengo acceso a datos en tiempo real, por lo que no puedo proporcionar la temperatura actual en Medellín. Sin embargo, puedo ofrecerte una estimación basada en el clima típico de la ciudad. Medellín, conocida como la \"Ciudad de la Eterna Primavera\", suele tener temperaturas agradables durante todo el año, generalmente entre 18°C y 28°C. En un día típico, la temperatura podría estar alrededor de 22°C a 24°C. Te recomendaría consultar una fuente de información meteorológica actualizada para obtener la temperatura exacta.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CASO A: LLM \"solo\"\n",
    "# -------------------------\n",
    "def llm_solo():\n",
    "    model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\",\n",
    "             \"Eres un asistente. Responde en español.\\n\"\n",
    "             \"Tarea: decir la temperatura actual de Medellín (°C).\\n\"\n",
    "             \"Regla: NO tienes datos en tiempo real. Debes decirlo explícitamente y dar una estimación razonable.\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | model\n",
    "    out = chain.invoke({\"question\": \"¿Cuál es la temperatura actual en Medellín (°C)?\"})\n",
    "\n",
    "    print(\"\\n=== CASO A: LLM sin tools (solo prompt) ===\")\n",
    "    print(out.content)\n",
    "\n",
    "llm_solo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5f75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='¿Cuál es la temperatura actual en Medellín (°C)?', additional_kwargs={}, response_metadata={}, id='51147eef-dcb7-4f58-8aa2-a5481c26f03b')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 122, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DEJmONysaRr15ocnPXFM8gNM5LV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ee0-5818-7083-be3f-7b602f9fc6d8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Medellín'}, 'id': 'call_WRy8iZyw3uywQCBDGo1y0PH3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 122, 'output_tokens': 16, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='¿Cuál es la temperatura actual en Medellín (°C)?', additional_kwargs={}, response_metadata={}, id='51147eef-dcb7-4f58-8aa2-a5481c26f03b'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 122, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DEJmONysaRr15ocnPXFM8gNM5LV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ee0-5818-7083-be3f-7b602f9fc6d8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Medellín'}, 'id': 'call_WRy8iZyw3uywQCBDGo1y0PH3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 122, 'output_tokens': 16, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='{\"city_input\": \"Medellín\", \"city_resolved\": \"Medellín, Colombia\", \"temperature_c\": 20.2, \"time\": \"2026-02-11T22:30\", \"source\": \"open-meteo\"}', name='get_weather', id='df490cec-038f-4edc-8af9-47d7bfa6c9ab', tool_call_id='call_WRy8iZyw3uywQCBDGo1y0PH3')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='¿Cuál es la temperatura actual en Medellín (°C)?', additional_kwargs={}, response_metadata={}, id='51147eef-dcb7-4f58-8aa2-a5481c26f03b'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 122, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DEJmONysaRr15ocnPXFM8gNM5LV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ee0-5818-7083-be3f-7b602f9fc6d8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Medellín'}, 'id': 'call_WRy8iZyw3uywQCBDGo1y0PH3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 122, 'output_tokens': 16, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"city_input\": \"Medellín\", \"city_resolved\": \"Medellín, Colombia\", \"temperature_c\": 20.2, \"time\": \"2026-02-11T22:30\", \"source\": \"open-meteo\"}', name='get_weather', id='df490cec-038f-4edc-8af9-47d7bfa6c9ab', tool_call_id='call_WRy8iZyw3uywQCBDGo1y0PH3')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='La temperatura actual en Medellín es de 20.2°C.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 200, 'total_tokens': 215, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DENvRNfojbJhkvFXa5bYu8qxXlo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ee0-6484-7663-97e6-84fbfb44f73e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 200, 'output_tokens': 15, 'total_tokens': 215, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='¿Cuál es la temperatura actual en Medellín (°C)?', additional_kwargs={}, response_metadata={}, id='51147eef-dcb7-4f58-8aa2-a5481c26f03b'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 122, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DEJmONysaRr15ocnPXFM8gNM5LV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ee0-5818-7083-be3f-7b602f9fc6d8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Medellín'}, 'id': 'call_WRy8iZyw3uywQCBDGo1y0PH3', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 122, 'output_tokens': 16, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"city_input\": \"Medellín\", \"city_resolved\": \"Medellín, Colombia\", \"temperature_c\": 20.2, \"time\": \"2026-02-11T22:30\", \"source\": \"open-meteo\"}', name='get_weather', id='df490cec-038f-4edc-8af9-47d7bfa6c9ab', tool_call_id='call_WRy8iZyw3uywQCBDGo1y0PH3'), AIMessage(content='La temperatura actual en Medellín es de 20.2°C.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 200, 'total_tokens': 215, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ad98c18a04', 'id': 'chatcmpl-D8DENvRNfojbJhkvFXa5bYu8qxXlo', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ee0-6484-7663-97e6-84fbfb44f73e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 200, 'output_tokens': 15, 'total_tokens': 215, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "La temperatura actual en Medellín es de 20.2°C.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CASO B: Agente (prompt + tools) SIN loop explícito\n",
    "# - create_agent maneja internamente el ciclo tool-calling/stop-condition\n",
    "# -------------------------\n",
    "def agente_con_tool():\n",
    "    model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    tools = [get_weather]\n",
    "\n",
    "    # ✅ “Toda la instrucción en un prompt” (system_prompt)\n",
    "    system_prompt = (\n",
    "        \"Eres un agente. Responde en español.\\n\"\n",
    "        \"Objetivo: dar la temperatura ACTUAL de Medellín (°C).\\n\"\n",
    "        \"Regla: para datos en tiempo real DEBES usar la herramienta get_weather.\\n\"\n",
    "        \"Si la herramienta falla, dilo y da una aproximación.\"\n",
    "    )\n",
    "\n",
    "    graph = create_agent(\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt,  # ✅ este es el parámetro correcto en 1.x\n",
    "        debug=True,                   # opcional: logs del runtime (útil en clase)\n",
    "    )\n",
    "\n",
    "    # ✅ invocación “messages-based”\n",
    "    result = graph.invoke(\n",
    "        {\"messages\": [HumanMessage(content=\"¿Cuál es la temperatura actual en Medellín (°C)?\")]}\n",
    "    )\n",
    "\n",
    "    # result[\"messages\"] trae todo el historial; el último suele ser la respuesta final\n",
    "    last = result[\"messages\"][-1]\n",
    "    print(getattr(last, \"content\", last))\n",
    "\n",
    "agente_con_tool()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentes_maestria_CD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
